# ü¶èüéì RAPPORT TP DEEP LEARNING - INSA Lyon 5IF üéìü¶è
###### _Paul-Emmanuel SOTIR \<paul-emmanuel.sotir@insa-lyon.fr\> ; \<paul-emmanuel@outlook.com\>_
- Course link https://perso.liris.cnrs.fr/christian.wolf/teaching/deeplearning/tp.html
- Github repository: https://github.com/PaulEmmanuelSotir/BallDetectionAndForecasting
  
### Introduction

L'objectif de ce projet est d'acquerir des connaissances autour de l'aspect empirique du deep learning. Ce projet est l'occasion de mieux maitriser le framework pytorch dans un cas d'utilisation simple mais relativement complet.  
Ce TP se divise en deux taches: impl√©menter un mod√®le √† base de r√©seaux neuronaux pour la detection de balles color√©es dans des images et un mod√®le de pr√©diction de la position future de balles.

Le dataset utilis√© dans ce projet est un sous-ensemble du dataset synth√©tique cr√©e pour les experimentations d√©crites dans le papier suivant : [_Fabien Baradel, Natalia Neverova, Julien Mille, Greg Mori, Christian Wolf. COPHY: Counterfactual Learning of Physical Dynamics. pre-print arXiv:1909.12000, 2019._](https://arxiv.org/abs/1909.12000).  
Une des particularit√©s de ce dataset que l'on a observ√©s lors de l'exploration des donn√©es est que toutes les images (100x100) ne comprenent que trois balles et chaques balles d'une m√™me image ont une couleur diff√©rente parmis les 9 couleurs possibles.  
J'ai √©galement p√ª observer une certaine redondance d'information de par la repr√©sentation des donn√©es utilis√©e: les bounding boxes des balles indiquent la couleur, de par leur position dans le tenseur, alors que les informations de couleurs sont d√©j√† pr√©sentes dans le vecteur de couleurs. Un des points important de ce TP est que le dataset est pens√© pour √©viter certaines difficult√©es communes √† la detection d'objet: avec un nombre constant de balles √† detecter, les mod√®les √† impl√©menter sont bien plus simples (pas d'approches r√©curantes (RCNN) ou similaires aux mod√®les de detection tels que SSD ou Yolo). De m√™me, il est peut-√™tre possible que la redondance des informations est la cons√©quence d'une d√©marche visant √† rendre l'entrainement plus simple sur les bounding boxes en donnant une s√©mantique claire et simple de l'emplacement et l'ordre des boundings boxes √† inferer (ordre/emplacement donn√© par la couleur). Ainsi, il n'y a pas besoin de penser une '_loss_' ou un post-traitement sp√©cifique qui renderais le mod√®le invariant √† l'ordre des bounding boxes (autrement, le mod√®le aurait plus de mal √† converger puisque m√™me si il inf√®re des bounding boxes parfaites, si elles sont donn√©es dans le 'mauvais ordre', alors l'erreur sera importante).

Pour une meilleure reproductibilit√© des r√©sultats, nous avons fix√© les seeds al√©atoires de ```numpy.random```, ```python.random```, de ```torch.manual_seed``` ainsi que ```torch.cuda.manual_seed_all```.

Les donn√©es fournies pour ce TP sont divis√©es en deux sous datasets associ√©s aux deux t√¢ches/parties de ce TP :

#### Tache 1 : detection de balles

Le but de cette premi√®re t√¢che est dans un premier temps d'impl√©menter un mod√®le la couleur des balles d'un image en entr√©e. Puis dans un second temps, d'ajouter au mod√®le entrain√©, l'inf√©rence des coordon√©es des bounding boxes donnant la position des balles dans l'image en entr√©e.

#### Tache 2 : pr√©diction de la position future de balles

La seconde partie de ce TP vise √† impl√©menter un mod√®le pouvant pr√©dire la position future de 3 balles √† partir d'une s√©quence de 19 observations dans le temps de la position des balles dans les images (pr√©diction de la 20√®me observation des balles). Ce mod√®le ne prend pas nescessairement d'image en entr√©e, seulement la s√©quence pass√©e de positions de balles et le vecteur de couleurs d'images suffisent (on suppose que l'image ne contient pas d'informations suppl√©mentaires sur le mouvement des balles).  

Entrainer un mod√®le sur cette seconde t√¢che am√®ne le mod√®le √† inf√®rer partiellement et implicitement les proprit√©t√©s physiques de la balles. En effet le dataset synth√©tique a √©t√© g√©n√©r√© en simulant le mouvement de balles avec des propri√©t√© physiques variables (masses, frottements, ect...) et ces param√®tres ne sont nullement disponnibles au del√† de l'observation du comportement de la balle. Ce dataset est pens√© pour que le probl√®me pos√© ne soit pas totalement r√©solvable ('_ill posed problem_') puisque les prori√©t√©s physiques des balles ne peuvent pas √™tre completement connues √† partir de la s√©quence seule.  

On peut aussi se poser la question, concerant le vecteur de couleurs des balles, de si les propri√©t√©s physiques des balles sont elles partielement correll√©es avec leur couleurs respective. Si on prend pour √†-priori qu'il n'y a pas de causalit√© alors on peut ignorer totalement les couleurs pour cette partie du TP.  
Nous faisons le choix de prendre le vecteur des couleurs en entr√©e de notre mod√®le. A suposer qu'il n'y a pas d'information pertinantes sur les mouvements de balles dans leur couleurs, il faut esp√®rer que le dataset ne pr√©sente pas de correlations sans causalit√© (nous n'avons pas explor√© cet aspect dans l'EDA) et que la r√©gularisation du mod√®le suffirat √† surmonter les l√©g√®res corr√©lation.

### Run instructions

Les d√©pendences du projets sont g√®r√©es avec un environement conda; Il suffit donc d'une distribution conda (e.g. Anconda ou Miniconda) et de cr√©er l'environement conda pour pouvoir executer le code. Les fichiers python __```../src/train.py```__ (entrainement d'un mod√®le avec les meilleurs hyperparam√®tres trouv√©s) et __```../src/hp.py```__ (recherche d'hyperparametres executant de nombreux entrainement sur moins d'epochs) sont les deux points d'entr√©e principals. Ces deux programmes doivent avoir pour argument __```--model detect```__ (t√¢che 1: detection de balles) ou __```--model forecast```__ (t√¢che 2: pr√©diction de position de balle future).  

Ci dessous les instructions d'installation et des exemples d'execution d'entrainements et de recherches d'hyperparametres sur les t√¢ches 1 et 2 :

``` shell
############## Installation ##############

git clone git@github.com:PaulEmmanuelSotir/BallDetectionAndForecasting.git
conda env create -f ./environement.yml
conda activate pytorch_5if
# T√©l√©charge les datasets (nescessite les packages 'curl' et 'tar' sur une distribution Linux (ou WSL - Linux subsystem on Windows))
bash ./download_dataset.sh

############## Exemples d'utilisation ##############

# Entraine le mod√®le de d√©tection de balles (tache 1) avec les meilleurs hyperparam√®tres trouv√©s
python -O ./src/train.py --model detect
# Execute une recherche d'hyperparam√®tres pour la detection de balles (hyperopt)
python -O ./src/hp.py --model detect | tee ./hp_detect.log
# Entraine le mod√®le de pr√©diction de position de balles (tache 2) avec les meilleurs hyperparam√®tres trouv√©s
python -O ./src/train.py --model forecast
# Execute une recherche d'hyperparam√®tres pour la pr√©diction de position de la balles (hyperopt)
python -O ./src/hp.py --model forecast | tee ./hp_forecast.log
```

Example d'entrainement du mod√®le de detection de balles :

``` shell
(pytorch_5if) pes@pes-desktop:~/BallDetectionAndForecasting$ python -O ./src/train.py --model detect
> Initializing and training ball detection model (mini_balls dataset)...
> __debug__ == False - Using 16 workers in each DataLoader...
> MODEL ARCHITECTURE:
BallDetector(
  (_layers): Sequential(
    (0): Sequential(
      (0): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1))
      (1): ReLU()
      (2): BatchNorm2d(4, eps=1e-05, momentum=0.07359778246238029, affine=True, track_running_stats=True)
    )
    (1): Sequential(
      (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1))
      (1): ReLU()
      (2): BatchNorm2d(4, eps=1e-05, momentum=0.07359778246238029, affine=True, track_running_stats=True)
    )
    (2): Sequential(
      (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1))
      (1): ReLU()
      (2): BatchNorm2d(4, eps=1e-05, momentum=0.07359778246238029, affine=True, track_running_stats=True)
    )
    (3): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)
    (4): Sequential(
      (0): Conv2d(4, 16, kernel_size=(5, 5), stride=(1, 1))
      (1): ReLU()
      (2): BatchNorm2d(16, eps=1e-05, momentum=0.07359778246238029, affine=True, track_running_stats=True)
    )
    (5): Sequential(
      (0): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1))
      (1): ReLU()
      (2): BatchNorm2d(16, eps=1e-05, momentum=0.07359778246238029, affine=True, track_running_stats=True)
    )
    (6): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)
    (7): Sequential(
      (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
      (1): ReLU()
      (2): BatchNorm2d(32, eps=1e-05, momentum=0.07359778246238029, affine=True, track_running_stats=True)
    )
    (8): Sequential(
      (0): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (1): ReLU()
      (2): BatchNorm2d(32, eps=1e-05, momentum=0.07359778246238029, affine=True, track_running_stats=True)
    )
    (9): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)
    (10): Sequential(
      (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
      (1): ReLU()
      (2): BatchNorm2d(64, eps=1e-05, momentum=0.07359778246238029, affine=True, track_running_stats=True)
    )
    (11): Flatten()
    (12): Sequential(
      (0): Linear(in_features=5184, out_features=45, bias=True)
      (1): Identity()
    )
  )
)
> MODEL CONVOLUTION FEATURE SIZES: [torch.Size([1, 4, 98, 98]), torch.Size([1, 4, 96, 96]), torch.Size([1, 4, 94, 94]), torch.Size([1, 16, 43, 43]), torch.Size([1, 16, 39, 39]), torch.Size([1, 32, 19, 19]), torch.Size([1, 32, 19, 19]), torch.Size([1, 64, 9, 9])]

Epoch 001/400
---------------
> Training on trainset 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1181/1181 [Elapsed=00:15, Remaining=00:00, Speed=75.31batch/s, batch_size=16, lr=6.537E-04, trainLoss=0.1971397]^[[B
>       Done: TRAIN_LOSS = 0.1971397
> Evaluation on validset   0%|                                                                                    | 0/131 [Elapsed=00:00, Remaining=?, Speed=?batch/s, BatchSize=16]> ! Saving visualization images of inference on some validset values...
> Evaluation on validset 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 131/131 [Elapsed=00:00, Remaining=00:00, Speed=192.49batch/s, BatchSize=16]
>       Done: VALID_LOSS = 0.1930378
>       Best valid_loss found so far, saving model...

Epoch 002/400
---------------
> Training on trainset 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1181/1181 [Elapsed=00:13, Remaining=00:00, Speed=87.46batch/s, batch_size=16, lr=6.537E-04, trainLoss=0.1557234]
>       Done: TRAIN_LOSS = 0.1540092
> Evaluation on validset   0%|                                                                                    | 0/131 [Elapsed=00:00, Remaining=?, Speed=?batch/s, BatchSize=16]> ! Saving visualization images of inference on some validset values...
> Evaluation on validset 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 131/131 [Elapsed=00:00, Remaining=00:00, Speed=193.57batch/s, BatchSize=16]
>       Done: VALID_LOSS = 0.1374522
>       Best valid_loss found so far, saving model...
...
...
...
```

Une fois les recherches d'hyperparam√®tres lanc√©es ou termin√©es, on peut utiliser les fonction outils __```balldetect.torch_utils.extract_from_hp_search_log()```__ et __```balldetect.torch_utils.summarize_hp_search()```__ pour explorer les r√©sultats d'une recherche d'hyperparam√®tres sur un notebook jupyter, par example (voir le notebook ```../notebooks/hp_search_results.ipynb```, les logs bruts situ√© dans le dossier [../docs/hp_search_logs/](../docs/hp_search_logs/), l'annexe √† la fin de ce rapport pour les r√©sultats des recherches d'hyperparam√®tres ou ```../src/hp.py``` pour l'impl√©mentation de la recherche d'hyperparam√®tres avec le module '__hyperopt__').

### Developement et documentation

#### Architecture du projet

Le projet est constitu√© d'un module Python 'balldetect' contenant :

- L'impl√©mentation (d√©finition, entrainement, √©valuation) des deux mod√®les r√©solvant les t√¢ches 1 et 2 (../src/balldetect/ball_detector.py et ../src/balldetect/seq_prediction.py)
- Le code pour charger/pr√©traiter les datasets (../src/balldetect/datasets.py)
- torch_utils.py contenant diverses fonction r√©utilisables, notamment pour la d√©finition et entrainement d'un mod√®le pytorch
- Et √©galement un fichier fournit facilitant la visualisation des images avec ou sans bounding boxes (../src/balldetect/vis.py)

Les fichiers ../src/train.py et ../src/hp.py sont les points d'entr√©e pour, respectivement, l'entrainement d'un mod√®le (detection ou forecasting) avec les meilleurs param√®tres trouv√©s et la recherche d'hyperparam√®tres (detction ou forecasting) cherchant les meilleurs hyperparam√®tres 'sampled' dans un espace d√©finit.

Organisation du dossier du projet :
``` python
- BallDetectionAndForecasting
  - src/                        # Code source du projet
    - balldetect/               # Module 'balldetect'
      - __init__.py
      - ball_detector.py        # Mod√®le de detection de balles (t√¢che 1)
      - datasets.py             # Objets datasets (fourni), cr√©ation des dataloaders et fonction 'retrieve_data'
      - seq_prediction.py       # Mod√®le de pr√©diction de position de balles (t√¢che 2)
      - torch_utils.py          # Fonctions d√©finissant du code commun r√©utilisable: Couches de convolution ou denses; parralelize; Flatten ; tqdm personnalis√©; ... 
      - vis.py                  # Visualization des images avec boundings boxes (fourni)
    - train.py                  # Code utilisant le module 'balldetect' pour entrainer le mod√®le de detection ou de pr√©diction de position de balles
    - hp.py                     # Code de recherche d'hyperparam√®tres
  - notebooks/
    - hp_search_results.ipynb  # Notebook inspectant le r√©sultat des recherches d'hyperparam√®tres
    - test_fastai.ipynb         # Notebook 'brouillon' testant une approche pr√©liminaire au TP avec fastai (tache 1.1)
    - test_fastai-bbox.ipynb    # Notebook 'brouillon'testant une approche pr√©liminaire au TP avec fastai (tache 1.2: version avec bounding-boxes)
  - datasets/
    - mini_balls/
    - mini_balls_seq/
  - docs/
    - figures/                  # Dossier d'images/figures contenues dans ce rapport
    - hp_search_logs/           # Dossier des logs d'execution des recherches d'hyperparam√®tres ('../src/hp.py')
    - rapport.md                # Ce rapport au format originel (markdown)
    - hp_search_results.html    # Annexe issue du notebook du m√™me nom
    - ...                       # Diverses versions du rapport et de l'annexe export√©es en PDF et HTML
  - README.md
  - LICENSE
  - environement.yml            # Environement conda, d√©finit les d√©pendances
  - download_dataset.sh         # Script de t√©l√©chargement des datasets
  - .gitignore
```

#### Tests pr√©liminaires avec fastai (voir notebooks 'brouillons' ```test_fastai.ipynb``` ```test_fastai-bbox.ipynb```)

Dans un premier temps, avant de coder l'approche avec des mod√®les Pytorch personalis√©s. Des premiers tests on √©t√© fait avec fastai pour avoir une id√©e de la difficult√© de la premi√®re t√¢che et ainsi avoir une baseline. L'approche avec fastai, certes tr√®s peut didactique ou optimis√©e en termes de taille de mod√®le, permet des r√©sultats assez corrects de mani√®re tr√®s rapide. Il s'agissait de tester des mod√®les connus (e.g. variantes de ResNet) pr√©entrainn√©s sur des images ImageNet ou autre. Un rapide fine-tunning sur le dataset de d√©t√©ction de balles permet d'obtenir un detection raisonable en 3-4 lignes de code.  
Une des fonctionalit√©s √©galement interessantes de fastai est l'impl√©mentation d'un m√©thode pour d√©terminer un meilleur learning rate sans avoir √† executer une recherche d'hyperprametres classique (type random-search): le learning rate est d√©termin√© le temps d'une seule √©poque en changeant le learning rate √† chaque batch d'entrainement (voir [callbacks.lr_finder de fastai](https://docs.fast.ai/callbacks.lr_finder.html)).  
Cette approche pr√©liminaire a permit de mieux connaitre les avantages et inconv√©nients d'une utilisation tr√®s basique de fastai (en effet, fastai n'emp√™che pas un controle complet sur le mod√®le entrain√© et la proc√©dure d'entrainement). Les r√©sultats obtenus permettent dans la suite de pouvoir mieux interpreter les valeurs des m√©triques sur ce dataset (donne une baseline raisonnable).


#### Petites optimizations du code

- Le(s) GPU disponnibles seront utilis√©s automatiquement si possible: 

``` python
# Device donn√© en argument de la fonction '.to(DEVICE)' des torch.Tensor
DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
```

- Les dataloaders utilisent plusieur sous-processus en fonction du nombre de coeurs CPU disponnibles sur la machine (param√®tre __```num_workers```__ des Dataloader-s) :

``` python
# Nombre de 'thread' utilis√©s pour chaque dataloader
_DEFAULT_WORKERS = 0 if __debug__ else min(os.cpu_count() - 1, max(1, os.cpu_count() // 4) * max(1, torch.cuda.device_count()))
```

- Pour une meilleure optimization des op√©rations de Pytorch sur GPU, on peut activer l'auto-tuning (bas√© sur un benchmark) de la librairie CuDNN s'ajoutant √† CUDA. CuDNN est une librairie de NVidia (un fichier cpp et une header C++ ajout√© au toolkit CUDA) qui offre des optimisations sp√©cifiques aux r√©seaux de neurones (Convolutions, produits de matrices, calcul du gradient, ...). CuDNN est int√©gr√© √† Pytorch comme pour CUDA qui est simplement une d√©pendance install√©e dans l'environement Conda. 
Pytorch permet d'am√©liorer les performances de CuDNN d'avantage avec les param√®tres __```cudnn.benchmark```__ et __```cudnn.fastest```__. Cependant, activer le benchmarking de CuDNN dans Pytorch peut impacter la reproducibilit√© des r√©sultats √©tant donn√© que ce n'est pas un processus d√©terministe (m√™me avec __```torch.backends.cudnn.deterministic = True```__).  
On observe une am√©lioration de la vitesse d'entrainement entre 30% et 40% pour les mod√®les Pytorch de detection et de pr√©diction de position de balles:

``` python
# Torch CuDNN configuration
torch.backends.cudnn.deterministic = True
cudnn.benchmark = torch.cuda.is_available()  # Enable builtin CuDNN auto-tuner, TODO: benchmarking isn't deterministic, disable this if this is an issue (and disable parallelization to which isn't deterministic neither)
cudnn.fastest = torch.cuda.is_available()  # Disable this if memory issues
```

- Les performances ont aussi √©t√© un facteur important dans les choix d'hyperparam√®tres et d'architecture des mod√®les (espace de recherche des hyperparametres avec hyperopt). Par exemple, l'architecture du detecteur contient des couches de convolution avec du _average pooling_ (remplacant le 'stride' de 2 dans les derni√®res variantes du mod√®le) pour r√©duire la quantit√©e de param√®tres et de features √† traiter. Les deux mod√®les ont un nombre total de couches relativement faibles. Pareillement, le nombre de filtres de convolution, la taille des filtres (3x3 ou, plus haut dans la convolution, 5x5) et la largeur des couches fully-connected ont √©t√© choisis, en autre, pour √™tre assez faibles √©tant donn√© la simplicit√© aparante de la t√¢che de d√©tection et pour permettre un entrainement plus rapide.

- Les entrainements des mod√®les sont √©galement acc√©l√©r√©s en parallelisant les 'training steps' sur plusieurs GPUs automatiquement avec __``` model = nn.DataParallel(model) ```__ (voir la fonction __``` paralellize(model: nn.Module) -> nn.Module ```__ dans __```../src/balldetect/torch_utils.py```__). Les mod√®les ont √©t√© entrain√© sur une machine personnelle dot√©e de deux NVidia 1080 ti; La paral√®llisation des donn√©es avec cette fonction automatique de Pytorch vas donc executer deux entrainements en parall√®le et synchroniser les gradients √† chaque √©tapes de mani√®re synchrone en calculant la moyenne des deux 'training steps' avant de passer √† l'entrainement sur les prochains batchs.  
De par le besoin de synchronisation des gradients, le mod√®le et/ou les donn√©es/batch_size doivent √™tre assez volumineux pour que cette parall√®lisation offre une acc√©l√©ration de l'entrainement par rapport √† l'utilisation d'un seul GPU.  
Par exemple, on observe pour le mod√®le de detection de balles qu'il faut une __```batch_size```__ souvent sup√©rieure √† 64 pour que les deux 1080 ti soit utilis√©es au del√† de 50% (nvidia-smi). Cependant, trop augmenter la batch_size peut poser des probl√®mes, notamment √† cause de la taille limit√©e du dataset et, pour des mod√®les plus importants, pourrais demander une quantit√©e de m√©moire vid√©o trop grande.  

#### Tache 1: Mod√®le de detection de balles (voir [../src/balldetect/ball_detector.py](../src/balldetect/ball_detector.py) et les hyperparam√®tres associ√©s dans [../src/train.py](../src/train.py))

Le mod√®le que nous avons construit pour la d√©tection de balles devait dans un premier temps ne d√©tecter que les couleurs de balles et non leur positions dans l'image (bounding boxes).  
Dans un second temps, nous avons modifi√© le mod√®le pour inf√©rer √©galement les bounding boxes. Les donn√©es issues du dataset ayant une redondance, en autre, au niveau des couleurs de balles (information de couleur pr√©sente √† la fois dans l'ordre des bounding boxes et dans le vecteur de couleurs), nous avons impl√©ment√© deux alternative : 

- Une premi√®re o√π le mod√®le est entrain√© directement √† inf√®rer les 9 bounding boxes ainsi que le vecteur de couleurs (dont 6 sont √† 0 pour une image donn√©e)
- Une seconde variant o√π les bounding boxes sont pr√©trait√©e pour en enlever les vecteurs nuls : seul 3 bounding boxes sont inf√©r√©es en plus du vecteur de couleurs (le vecteur de couleurs inf√©r√© alors par le mod√®le d√©finit la position bounding boxes en sortie (voir __```BallsCFDetection.__getitem__```__ et __```retrieve_data```__ dans [../src/balldetect/datasets.py](../src/balldetect/datasets.py)) : le mod√®le fait donne donc en sortie une r√©gression de 3 bounding boxes (3x4 coordonn√©es) et une _multi-label classsification_ pour donner en sortie le vecteur de couleurs (9 valeurs binaires, dont 3 sont √† 1 et les autres √† 0)  

J'ai √©galement test√© rappidement une autre alternative o√π seul les bounding boxes sont inf√©r√©es et la couleur est d√©duite de la position des trois vecteurs de coordonn√©es maximaux; Mais √©tant donn√© que la t√¢che demand√©e dans le sujet implique que le mod√®le inf√®re √† la fois le vecteur de couleurs et les boudning boxes (d'apr√®s ma compr√©hension du sujet), je n'ai pas explor√© cette variante d'avantage.  

Un r√©sultat interessant que j'ai p√ª observer est qu'inf√©rer seulement 3 bounding boxes au lieu de 9 dont 6 nulles n'am√©liore pas forc√©ment les performances du mod√®le, voir le contraire. Cette observation peut avoir plusieur explication :  
Comme expliqu√© √† l'introduction, la structure de donn√©es pour les bounding boxes dans une matrice de 9 vecteurs de coordon√©es est plus simple/claire au niveau de l'ordre/position des vecteurs de coordonn√©es, alors que l'inf√©rence de 3 bounding boxes, m√™me avec l'ordre initial conserv√©, a moins de sens.  
Il est √©galement possible que ce r√©sultat soit d√ª √† d'autres probl√®mes dans le mod√®le qui ont √©t√© r√©soluts par la suite, sans avoir r√©√©valu√© l'interet de cette simplification des bounding boxes.

La loss utilis√©e pour entrainer le mod√®le est l'addiction de deux termes/m√©triques :  

- Le premier terme de la loss est la m√©trique BCE (**_Binary Cross Entropy_**) √©valuant la qualit√© de la classification 'multi-label' sur le vecteur binaire de couleurs.  Ce terme est multipl√© un hyperparam√®tre avant d'√™tre ajout√© au deuxi√®me terme de la loss (facteur souvent mis √† : __```bce_loss_scale=0.1```__)  
- Le second terme est la m√©trique MSE (**_Mean Squared Error_**) minimisant l'erreur au quarr√© moyenne sur la r√©gression des coordonn√©es des bounding boxes.


Le mod√®le est compos√© d'un '_convolution backbone_' suivit d'une ou plusieurs couches denses (_fully connected layer_). L'architecture du mod√®le contient √©galement des couches __```nn.AvgPooling2d```__ dans le *backbone* de convolutions.  
Nous avons impl√©ment√© l'architecture de mani√®re relativement g√©n√©rique de mani√®re √† pouvoir en d√©finir facilement des variantes dans les hyperparam√®tres.  

Une couche de convolution ou dense (__```nn.Conv2d```__ ou __```nn.Linear```__) peut-√™tre compos√©e d'une fonction d'activation (hyperparametre __```architecture.act_fn```__), de _dropout_ (si __```architecture.dropout_prob != 1.```__), de _batch normalization_ (si __```architecture.batch_norm```__ d√©finit les param√®tres __'eps'__ et __'momentum'__). Voir [../src/balldetect/torch_utils.py](../src/balldetect/torch_utils.py) pour plus de d√©tails sur l'impl√©mentation des couches.  
Pour ce mod√®le, nous avons principalement explor√© les fonctions d'activation __```nn.ReLU```__ et __```nn.LeakyReLU```__.
Les tailles de filtres de convolutions consid√®r√©es sont principalement de __3x3__, __5x5__ et parfois __7x7__ et __1x1__ (avec des padding correspondant). Nous avons √©galement explor√© l'utilisation de stride √† 2 ou 4 avant de remplacer cette pratique par de l'average pooling.  

Le Mod√®le a √©t√© entrain√© sur le dataset __```mini_balls```__ compos√© de 20000 images. Le dataset est d√©coup√© al√©atoirement en un 'trainset' (90% du dataset) et un 'validset' (10% du dataset). Malheureusement, nous n'avons pas eu le temps d'implementer une cross-validation qui aurais √©t√© utile √©tant donn√© la petite taille du dataset. En effet, dans cette configuration, le validset est un peu trop petit et il risque d'y avoir des instabilit√©s sur les valeurs des m√©triques d'√©valuation qui pourrait, en autre, fausser la recherche d'hyperparam√®tres. De plus, nous n'avons pas cr√©√© de 'testset' pour une √©valuation plus ponctuelle par crainte de perdre d'avantage de donn√©es d'entrainement avec un dataset de cette taille. Cepandant, il aurait peut-√™tre √©t√© pertinant d'en cr√©er un pour mesurer la pr√©sence d'overfitting sur le validset d√ª √† la recherche d'hyperparametres.  

La recherche d'hyperparam√®tre √† permit de trouver de bien meilleurs param√®tres d'entrainement et choisir la bonne variante d'architecture parmit celles d√©finies dans l'espace d'hyperparam√®tres. Nous avons p√ª d√©finir plusieurs espaces d'hyperparam√®tres relativement restreints √† la lumi√®re des r√©sultats obtenus avec des param√®tres d√©finit subjectivement.  
Ci-dessous, les deux derniers espace de recherche d'hyperparam√®tres utilis√©s avec hyperopt pour la d√©tection de balles dans __```../src/hp.py```__ (algorithme __```tpe.suggest```__ avec 2x100 entrainements de 90 epochs et un early_stopping de 12 epochs):

__L'un des premiers espace de recherche d'hyperparam√®tres utilis√© :__

__> NOTE: _L'architecture est d√©finie ici (par ```'conv2d_params'``` et ```'fc_params'```) de mani√®re diff√©rente du code actuel, de par un refactoring rendant plus g√©n√©rique la d√©finition de l'architecture avec les hyperparm√®tres (legacy hp search space)_ :__ 

``` python
hp_space = {
    'optimizer_params': {'lr': hp.uniform('lr', 5e-6, 1e-4), 'betas': (0.9, 0.999), 'eps': 1e-8,
                         'weight_decay': hp.loguniform('weight_decay', math.log(1e-7), math.log(1e-3)), 'amsgrad': False},
    'scheduler_params': {'step_size': 40, 'gamma': 0.2}, # LR Steps
    #'scheduler_params': {'max_lr': 1e-2, 'pct_start': 0.3, 'anneal_strategy': 'cos'}, # One cycle policy
    'batch_size': hp.choice('batch_size', [32, 64, 128]),
    'architecture': {
        'act_fn': nn.LeakyReLU,
        'dropout_prob': hp.choice('dropout_prob', [1., hp.uniform('nonzero_dropout_prob', 0.45, 0.8)]),
        # 'batch_norm': {'eps': 1e-05, 'momentum': 0.1, 'affine': True},
        # Convolutional backbone block hyperparameters
        'conv2d_params': hp.choice('conv2d_params', [
            [{'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1, 'stride': 2},
                {'out_channels': 8, 'kernel_size': (5, 5), 'padding': 2},
                {'out_channels': 8, 'kernel_size': (7, 7), 'padding': 3}],

            [{'out_channels': 2, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1, 'stride': 2},
                {'out_channels': 8, 'kernel_size': (5, 5), 'padding': 2},
                {'out_channels': 8, 'kernel_size': (5, 5), 'padding': 2, 'stride': 2},
                {'out_channels': 16, 'kernel_size': (7, 7), 'padding': 3}],

            [{'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 8, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 8, 'kernel_size': (3, 3), 'padding': 1, 'stride': 2},
                {'out_channels': 16, 'kernel_size': (5, 5), 'padding': 2}],

            [{'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1, 'stride': 4},
                {'out_channels': 8, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 8, 'kernel_size': (3, 3), 'padding': 1}]
        ]),
        # Fully connected head block hyperparameters (a final FC inference layer with no dropout nor batchnorm will be added when ball detector model is instantiated)
        'fc_params': hp.choice('fc_params', [[{'out_features': 64}],
                                                [{'out_features': 64}, {'out_features': 128}],
                                                []])}
}
```

__Second/dernier espace de recherche d'hyperparam√®tres (architecture des convolutions fix√©e):__
``` python
# Ball detector Conv2d backbone layers (nouvelle fa√ßon de d√©finir l'architecture)
conv_backbone = (
      ('conv2d', {'out_channels': 4, 'kernel_size': (3, 3), 'padding': 0}),
      ('conv2d', {'out_channels': 4, 'kernel_size': (3, 3), 'padding': 0}),
      ('conv2d', {'out_channels': 4, 'kernel_size': (3, 3), 'padding': 0}),
      ('avg_pooling', {'kernel_size': (2, 2), 'stride': (2, 2)}),
      ('conv2d', {'out_channels': 16, 'kernel_size': (5, 5), 'padding': 0}),
      ('conv2d', {'out_channels': 16, 'kernel_size': (5, 5), 'padding': 0}),
      ('avg_pooling', {'kernel_size': (2, 2), 'stride': (2, 2)}),
      ('conv2d', {'out_channels': 32, 'kernel_size': (5, 5), 'padding': 2}),
      ('conv2d', {'out_channels': 32, 'kernel_size': (7, 7), 'padding': 3}),
      ('avg_pooling', {'kernel_size': (2, 2), 'stride': (2, 2)}),
      ('conv2d', {'out_channels': 64, 'kernel_size': (5, 5), 'padding': 2}),
      ('flatten', {}))

# Define hyperparameter search space (second hp search space iteration) for ball detector (task 1)
detect_hp_space = {
    'optimizer_params': {'lr': hp.uniform('lr', 1e-6, 1e-3), 'betas': (0.9, 0.999), 'eps': 1e-8,
                         'weight_decay': hp.loguniform('weight_decay', math.log(1e-7), math.log(3e-3)), 'amsgrad': False},
    'scheduler_params': {'step_size': 40, 'gamma': .3},
    # 'scheduler_params': {'max_lr': 1e-2, 'pct_start': 0.3, 'anneal_strategy': 'cos'},
    'batch_size': hp.choice('batch_size', [16, 32, 64]),
    'bce_loss_scale': 0.1,
    'early_stopping': 12,
    'epochs': 90,
    'architecture': {
        'act_fn': nn.ReLU,
        'batch_norm': {'eps': 1e-05, 'momentum': hp.uniform('momentum', 0.05, 0.15), 'affine': True},
        'dropout_prob': hp.choice('dropout_prob', [0., hp.uniform('nonzero_dropout_prob', 0.1, 0.45)]),
        'layers_param': hp.choice('layers_param', [(*conv_backbone, ('fully_connected', {'out_features': 64}),
                                                    ('fully_connected', {})),
                                                    (*conv_backbone, ('fully_connected', {'out_features': 64}),
                                                    ('fully_connected', {'out_features': 128}),
                                                    ('fully_connected', {})),
                                                    (*conv_backbone, ('fully_connected', {'out_features': 128}),
                                                    ('fully_connected', {'out_features': 128}),
                                                    ('fully_connected', {})),
                                                    (*conv_backbone, ('fully_connected', {}))])
    }
}
```

La derni√®re recherche d'hyperparam√®tres √† donn√©es les param√®tres "optimaux" suivants (**```best_valid_loss=0.0031991```** apr√®s **82** epcohs) :  


``` python
{

DETECTOR_HP = {
    'batch_size': 16,
    'bce_loss_scale': 0.1,
    'early_stopping': 30,
    'epochs': 400,
    'optimizer_params': {'amsgrad': False, 'betas': (0.9, 0.999), 'eps': 1e-08, 'lr': 6.537177808319479e-4, 'weight_decay': 6.841231983628692e-06},
    'scheduler_params': {'gamma': 0.3, 'step_size': 40},
    'architecture': {
        'act_fn': nn.ReLU,
        'batch_norm': {'affine': True, 'eps': 1e-05, 'momentum': 0.07359778246238029},
        'dropout_prob': 0.0,
        'layers_param': (('conv2d', {'kernel_size': (3, 3), 'out_channels': 4, 'padding': 0}),
                         ('conv2d', {'kernel_size': (3, 3), 'out_channels': 4, 'padding': 0}),
                         ('conv2d', {'kernel_size': (3, 3), 'out_channels': 4, 'padding': 0}),
                         ('avg_pooling', {'kernel_size': (2, 2), 'stride': (2, 2)}),
                         ('conv2d', {'kernel_size': (5, 5), 'out_channels': 16, 'padding': 0}),
                         ('conv2d', {'kernel_size': (5, 5), 'out_channels': 16, 'padding': 0}),
                         ('avg_pooling', {'kernel_size': (2, 2), 'stride': (2, 2)}),
                         ('conv2d', {'kernel_size': (5, 5), 'out_channels': 32, 'padding': 2}),
                         ('conv2d', {'kernel_size': (7, 7), 'out_channels': 32, 'padding': 3}),
                         ('avg_pooling', {'kernel_size': (2, 2), 'stride': (2, 2)}),
                         ('conv2d', {'kernel_size': (5, 5), 'out_channels': 64, 'padding': 2}),
                         ('flatten', {}),
                         ('fully_connected', {}))
    }
}
```

**_> Voir les r√©sultats des recherches d'hyperparam√®tres en annexe pour plus de d√©tails sur leurs r√©sultats_**  

L'architecture de ce mod√®le obtenu avec la derni√®re recherche d'hyperparam√®tres est la suivante :

![detector_architecture2.png](./figures/detector_architecture2.png)

Nous avons ensuite entrain√© le mod√®le obtenu plus longement et chang√© le scheduling du learning rate pour permettre une meilleure convergance sur un plus grand nombre d'√©pochs en √©vitant l'overfitting: avec ces hyperpram√®tres un learning rate multipli√© par ```gamma=0.3``` toutes les **40** epochs d'entrainement, on obtient: **```best_train_loss=0.0005548```** et **```best_valid_loss=0.004782```** au bout de la 339√®me epoch.

Ci dessous quelques r√©sultats obtenus avec ce mod√®le sur des images du validset:  

![example_validset_inference.png](./figures/example_validset_inference.png)

On peut constater sur les exemples ci-dessus que le mod√®le de d√©tection de balle et de classification de ler couleur fonctionne, malgr√© quelques petites impr√©cisions sur la position exacte de la balle (underfitting l√©g√© sur les coordonn√©es).  

##### Tache 2: Mod√®le de pr√©diction de position de balles (voir ```../src/balldetect/seq_prediction.py``` et les hyperparam√®tres associ√©s dans ```../src/train.py```)

Le mod√®le de pr√©diction de position de balles est un simple r√©seaux de neurones dense (fully connected layers) puisque qu'il n'y a pas d'images en entr√©e du mod√®le.  

Pour simplifier l'entrainement du mod√®le, nous avons transform√© les donn√©es pour enlever la redondance d'information sur la couleur des balles. En effet, puisque la couleur des balles ne changent pas dans la s√©quence, nous entrainons le mod√®le pour ne pr√©dire que trois bounding boxes (la position des trois balles donn√©es en entr√©e).  
Nous enlevons donc les vecteurs nuls des boundings boxes en entr√©e (19 x 3 x 4 coordonn√©es) et des bounding box cibles (3 x 4 coordonn√©es). Nous donnons √©galement le vecteur de couleurs (de taille 9) au cas o√π la couleur des balles donerais de l'information sur les propri√©t√©s physiques des balles. Cette simplification des donn√©es permet une convergence bien plus rappide et meilleure.

Le mod√®le est un r√©seaux compos√© uniquement de couches denses (fully connected). Les couches sont d√©finies de mani√®re similaire aux couches denses du mod√®le de d√©tection (t√¢che 1) √† la diff√©rence pr√®s de la fonction d'activation utilis√©e : __```nn.tanh```__ et, biens√ªr, √† leur largeur pr√®s.  

La proc√©dure d'entrainement du mod√®le est relativement similaire √† celle du mod√®le de detection de la tache 1, aux hyperparam√®tres pr√®s. Le mod√®le est entrain√© sur le dataset __```../dataset/mini_balls_seq```__ avec une s√©paration al√©atoire entre validset (10% du dataset) et du trainset (90% du dataset), sans testset pour √©viter de perdre trop de donn√©es, √©tant donn√© la petite taille du dataset. Nous n'avons malheureusement pas p√ª travailler autant que voulut sur l'interpr√®tation de la qualit√© des pr√©dictions faites sur les positions des balles au del√† de la m√©trique utilis√©e, la MSE calcul√©e sur les trois bounding boxes de sortie normalis√©es par le vecteur ```balldetect.datasets.BBOX_SCALE```.  

Ci-dessous, l'espace de recherche d'hyperparam√®tres utilis√©e pour trouver les param√®tres de ce mod√®le:

``` python
{
    'optimizer_params': {'lr': hp.uniform('lr', 5e-6, 1e-4), 'betas': (0.9, 0.999), 'eps': 1e-8, 'weight_decay': hp.loguniform('weight_decay', math.log(1e-7), math.log(1e-2)), 'amsgrad': False},
    'scheduler_params': {'step_size': EPOCHS, 'gamma': 1.},
    # 'scheduler_params': {'max_lr': 1e-2, 'pct_start': 0.3, 'anneal_strategy': 'cos'},
    'batch_size': hp.choice('batch_size', [32, 64, 128]),
    'architecture': {
        'act_fn': hp.choice('batch_size', [nn.LeakyReLU, nn.ReLU, nn.Tanh]),
        'dropout_prob': hp.choice('dropout_prob', [1., hp.uniform('nonzero_dropout_prob', 0.45, 0.8)]),
        # Fully connected network hyperparameters (a final FC inference layer with no dropout nor batchnorm will be added when ball position predictor model is instantiated)
        'fc_params': hp.choice('fc_params', [[{'out_features': 512}, {'out_features': 256}] + [{'out_features': 128}] * 2,
                                              [{'out_features': 128}] + [{'out_features': 256}] * 2 + [{'out_features': 512}],
                                              [{'out_features': 128}] + [{'out_features': 256}] * 3,
                                              [{'out_features': 128}] * 2 + [{'out_features': 256}] * 3,
                                              [{'out_features': 128}] * 2 + [{'out_features': 256}] * 4,
                                              [{'out_features': 128}] * 3 + [{'out_features': 256}] * 4])}
}
```

Le meilleur mod√®le trouv√© √† pour hypererparam√®tres le dictionnaire suivant (**```best_valid_mse=0.0005018, best_train_mse=0.0005203, at 78th epoch over 90 epochs```**) :  

``` python
SEQ_PRED_HP = {
    'batch_size': 16,
    'early_stopping': 30,
    'epochs': 400,
    'optimizer_params': {'amsgrad': False, 'betas': (0.9, 0.999), 'eps': 1e-08, 'lr': 9.891933484569264e-05, 'weight_decay': 2.0217734556558288e-4},
    'scheduler_params': {'gamma': 0.3, 'step_size': 30},
    'architecture': {
        'act_fn': nn.Tanh,
        'dropout_prob': 0.44996724122672166,
        'fc_params': ({'out_features': 512},
                      {'out_features': 256},
                      {'out_features': 128},
                      {'out_features': 128})
    }
}
```

Une fois ce mod√®le entrain√© sur plus d'epochs et un learning rate scheduler adapt√©, avec [../src/train.py](../src/train.py), nous obtenons les r√©sultats suivants : __```best_valid_mse=0.0003570```__ et __```best_train_mse=0.0002038```__ au bout de la 270√®me epcoh d'entrainement (early stopping √† la 300√®me epoch).  

Malheureusement, malgr√© les dispositions sur la reproductibilit√©, si l'on relance l'entrainement, nous obtenons les r√©sultats suivants (peut-√™tre li√© √† l'optimisation de CuDNN non-deterministe) :  
**```best_train_mse=0.0005548```** et **```best_valid_mse=0.0004782```** √† la 173√®me epoch (early stopping √† la 203√®me epoch).

Je n'ai pas eu le temps de mieux interpr√™ter les valeurs de loss pour ce mod√®le et pour visualiser les s√©quences de bounding boxes inf√©r√©es.  

Il aurait aussi √©t√© interessant de voir le comportement du mod√®le si appliqu√© de mani√®re "r√©currente' en donnant pour s√©quence dn entr√©e les 18 derni√®res positions et la position inf√©r√©e pr√©c√©demment pour en d√©duire la position de la balle √† l'instant t+2 et ainsi de suite...  (plus ou moins simmilaire √† l'application d'un RNN avec une 'fen√™tre contextuelle' de 20√©tapes, mais sans features repr√©santant l''√©tats interne' du RNN)  

### Conclusion

Pour conclure, d√©velopper et tester des mod√®les Pytorch, certes simples, m'as permit d'approfondir mes connaissances en deep learning, notamment d'un point de vue pratique/technique.  

Il est regretable que l'interpretation des m√©triques et la visualisation des r√©sultats de la t√¢che 2 souffre d'un manque de temps (ou plut√¥t, est la cons√©quence des priot√©s donn√©es aux diff√©rents aspects du projet). Cepandant, nous avons p√ª d√©velopper des mod√®les Pytorch et des proc√©dures d'entrainement assez fonctionels, complets, g√©n√©rique et r√©utilisables. En effet, ce projet a √©galement √©t√© l'occasion poser une base de code relativement solide pour de futurs projets en Pytorch.

#### Autres pistes et am√©liorations possibles

+ travailler d'avantage sur l'interpr√®tation et l'investigation des m√©triques: calculer des m√©triques plus interpretables que la loss de la t√¢che 1 qui n'est pas vraiment interpretable en l'√©tat.
+ exploiter d'avantage d'a prioris sur le vecteur des couleurs lors de la detection de balles de la t√¢che 1 : sur les 9 valeurs binaires du vecteur de couleurs, 3 sont √† 1 et les autres √† 0, or, notre mod√®le est entrain√© pour faire une classification multi-classes (vecteur de couleurs en sortie de taille 9 avec une binary cross-entropy loss) alors qu'il pourait s'agir de classifier 3 valeurs (comprises entre 0 et 8) repr√©santant les index des 3 valeurs √† 1 dans le vecteur de couleurs. Cepandant, il n'est pas certains que cette approche am√©liorerais les performances puisque pr√©dire une 'simili-lookup table' (ou embedding layer) a ses avantages : empiriquement on constate souvent que la qualit√© des pr√©dictions est meilleures ainsi (probablement car les gradients sont moins 'intriqu√©s' en sortie et chaque possiblit√©es de classification √† une sortie d√©di√©e, donc un parcours dans le r√©seaux plus ind√©pendant).
+ finir l'impl√©mentation de la sauvegarde de mod√®les et du logging des m√©triques pour tensorboard (utilisation de tensorboard avec Pytorch pour mieux diagnostiquer et visualiser l'entrainement).
+ exploiter l'as prioris sur les coordonn√©es des bounding boxes: non seulement les coordonn√©es sont dans un certain ordre mais, dans ce dataset, toutes les balles sont environs de la m√™me taille, on pourrait donc simplement faire une regression sur, par exemple, la moyennes des deux coordonn√©es d'une bounding box (centre de la balle). De mani√®re moins agressive, on pourrait aussi ajouter un terme dans la loss encouragant un certain ordre entre les valeurs des coordonn√©es des bounding boxes.
+ utiliser la mean average precision combin√©e avec une m√©trique _d'Intersection over Union_ (IoU) pour la regression des bounding boxes, comme utilis√©e sur le dataset Pascal VOC
+ utiliser de la cross validation √©tant donn√© la petite taille du dataset
+ cr√©er un petit testset pour √©valuer tr√®s ponctuellement le mod√®le autrement que par le validset qui pourrait √™tre compromis par la recherche d'hyperparam√®tres
+ utiliser des m√©thodes de recherche d'hyperparam√®tres plus efficaces (e.g. la m√©thode utilis√©e par fastai dans [callbacks.lr_finder](https://docs.fast.ai/callbacks.lr_finder.html): [post de blog de Sylvain Gugger](https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html)) et utilisation de [microsoft/nni](https://github.com/microsoft/nni) regroupant de nombreuses de m√©thodes de recherche d'hyperparam√®tres)
+ utiliser des m√©thodes de recherche d'architecture automatiques (beaucoup d'engouement/progr√®s dans la communaut√© deeplearning autour des m√©thodes de "neural net architecture search" et "meta-learning")
+ tests plus pouss√©s du scheduling de learning rate (e.g. investiger pourquoi OneCycle learning rate scheduler n'a pas donn√© de r√©sultats probants sur la d√©tection de balles avec notre mod√®l)
+ utiliser de l'augmentation de donn√©es aurait p√ª √™tre int√©ressant
+ comparer les r√©sultats et approches avec le papier https://arxiv.org/pdf/1909.12000.pdf

<img width=250 src="./figures/logo_insa.jpg"/>

*Copyright (c) 2019 Paul-Emmanuel SOTIR*  
*__This project and document is under open-source MIT license, browse to: https://github.com/PaulEmmanuelSotir/BallDetectionAndForecasting/blob/master/LICENSE for full MIT license text.__*

# Annexe : recherches d'hyperparam√®tres
## [Hyperparameter search results visualization notebook](../notebooks/hp_search_results.ipynb)
Or alternatively, view the thml version of this document with hyperprameter search results visualization at []() or the pdf version here: [](./