# ü¶èüéì RAPPORT TP DEEP LEARNING - INSA Lyon 5IF üéìü¶è
###### _Paul-Emmanuel SOTIR \<paul-emmanuel.sotir@insa-lyon.fr\> ; \<paul-emmanuel@outlook.com\>_
- Course link https://perso.liris.cnrs.fr/christian.wolf/teaching/deeplearning/tp.html
- Github repository: https://github.com/PaulEmmanuelSotir/BallDetectionAndForecasting
  
### Introduction

L'objectif de ce projet est d'acquerir des connaissances autour de l'aspect empirique du deep learning. Ce projet est l'occasion de mieux maitriser le framework pytorch dans un cas d'utilisation simple mais relativement complet.  
Ce TP se divise en deux taches: impl√©menter un mod√®le √† base de r√©seaux neuronaux pour la detection de balles color√©es dans des images et un mod√®le de pr√©diction de la position future de balles.

Le dataset utilis√© dans ce projet est un sous-ensemble du dataset synth√©tique cr√©e pour les experimentations d√©crites dans le papier suivant : [_Fabien Baradel, Natalia Neverova, Julien Mille, Greg Mori, Christian Wolf. COPHY: Counterfactual Learning of Physical Dynamics. pre-print arXiv:1909.12000, 2019._](https://arxiv.org/abs/1909.12000).  
Une des particularit√©s de ce dataset que l'on a observ√©s lors de l'exploration des donn√©es est que toutes les images (100x100) ne comprenent que trois balles et chaques balles d'une m√™me image ont une couleur diff√©rente parmis les 9 couleurs possibles. On a √©galement p√ª observer une certaine redondance d'information de par la repr√©sentation des donn√©es utilis√©e: les bounding boxes des balles indiquent la couleur, de par leur position dans le tenseur, alors que les informations de couleurs sont d√©j√† pr√©sentes dans le vecteur de couleurs. Un des points important de ce TP est que le dataset est pens√© pour √©viter certaines difficult√©es communes √† la detection d'objet: avec un nombre constant de balles √† detecter, les mod√®les √† impl√©menter sont bien plus simples (pas d'approches r√©curantes (RCNN) ou similaires aux mod√®les de detection tels que SSD ou Yolo)  

Pour une meilleure reproductibilit√© des r√©sultats, nous avons fix√© les seeds al√©atoires de ```numpy.random```, ```python.random```, de ```torch.manual_seed``` ainsi que ```torch.cuda.manual_seed_all```.

Les donn√©es fournies pour ce TP sont divis√©es en deux sous datasets associ√©s aux deux t√¢ches/parties de ce TP :

##### Tache 1 : detection de balles

Le but de cette premi√®re t√¢che est dans un premier temps d'impl√©menter un mod√®le la couleur des balles d'un image en entr√©e. Puis dans un second temps, d'ajouter au mod√®le entrain√©, l'inf√©rence des coordon√©es des bounding boxes donnant la position des balles dans l'image en entr√©e.

##### Tache 2 : pr√©diction de la position future de balles

La seconde partie de ce TP vise √† impl√©menter un mod√®le pouvant pr√©dire la position future de 3 balles √† partir d'une s√©quence de 19 observations dans le temps de la position des balles dans les images (pr√©diction de la 20√®me observation des balles). Ce mod√®le ne prend pas nescessairement d'image en entr√©e, seulement la s√©quence pass√©e de positions de balles et le vecteur de couleurs d'images suffisent (on suppose que l'image ne contient pas d'informations suppl√©mentaires sur le mouvement des balles).  

Entrainer un mod√®le sur cette seconde t√¢che am√®ne le mod√®le √† inf√®rer partiellement et implicitement les proprit√©t√©s physiques de la balles. En effet le dataset synth√©tique a √©t√© g√©n√©r√© en simulant le mouvement de balles avec des propri√©t√© physiques variables (masses, frottements, ect...) et ces param√®tres ne sont nullement disponnibles au del√† de l'observation du comportement de la balle.  

On peut aussi se poser la question concerant le vecteur de couleurs des balles de si les propri√©t√©s physiques des balles sont elles partielement correll√©es avec leur couleurs respective. Si on prend pour √†-priori qu'il n'y a pas de causalit√©  alors on peut ignorer totalement les couleurs pour cette partie du TP. Nous faisons le choix de prendre le vecteur des couleurs en entr√©e de notre mod√®le. A suposer qu'il n'y a pas d'information pertinantes sur les mouvements de balles dans leur couleurs, il faut esp√®rer que le dataset ne pr√©sente pas de correlations sans causalit√© (nous n'avons pas explor√© cet aspect dans l'EDA) et que la r√©gularisation du mod√®le suffirat √† surmonter les l√©g√®res corr√©lation.

### Run instructions

Les d√©pendences du projets sont g√®r√©es avec un environement conda; Il suffit donc d'une distribution conda (e.g. Anconda ou Miniconda) et de cr√©er l'environement conda pour pouvoir executer le code. Les fichiers python __```./src/train.py```__ (entrainement d'un mod√®le avec les meilleurs hyperparam√®tres trouv√©s) et __```./src/hp.py```__ (recherche d'hyperparametres executant de nombreux entrainement sur moins d'epochs) sont les deux points d'entr√©e principals. Ces deux programmes doivent avoir pour argument __```--model detect```__ (t√¢che 1: detection de balles) ou __```--model forecast```__ (t√¢che 2: pr√©diction de position de balle future).  

Ci dessous les instructions d'installation et des exemples d'execution d'entrainements et de recherches d'hyperparametres sur les t√¢ches 1 et 2 :

``` shell
############## Installation ##############

git clone git@github.com:PaulEmmanuelSotir/BallDetectionAndForecasting.git
conda env create -f ./environement.yml
conda activate pytorch_5if
# T√©l√©charge les datasets (nescessite les packages 'curl' et 'tar' sur une distribution Linux (ou WSL - Linux subsystem on Windows))
bash ./download_dataset.sh

############## Exemples d'utilisation ##############

# Entraine le mod√®le de d√©tection de balles (tache 1) avec les meilleurs hyperparam√®tres trouv√©s
python -O ./src/train.py --model detect
# Execute une recherche d'hyperparam√®tres pour la detection de balles (hyperopt)
python -O ./src/hp.py --model detect | tee ./hp_detect.log
# Entraine le mod√®le de pr√©diction de position de balles (tache 2) avec les meilleurs hyperparam√®tres trouv√©s
python -O ./src/train.py --model forecast
# Execute une recherche d'hyperparam√®tres pour la pr√©diction de position de la balles (hyperopt)
python -O ./src/hp.py --model forecast | tee ./hp_forecast.log
```

Example d'entrainement du mod√®le de detection de balles :

``` shell
(pytorch_5if) pes@pes-desktop:~/BallDetectionAndForecasting/$ python -O ./src/train.py --model detect

> Initializing and training ball detection model (mini_balls dataset)...
> __debug__ == False - Using 16 workers in each DataLoader...

Epoch 001/250
---------------
> Training on trainset 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 647/647 [Elapsed=00:07, Remaining=00:00, Speed=84.75batch/s, lr=9.962E-05, trainLoss=0.7427835]
>       Done: TRAIN_LOSS = 0.7416355
> Evaluation on validset 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [Elapsed=00:00, Remaining=00:00, Speed= 1.20batch/s, BatchSize=8192]
>       Done: VALID_LOSS = 0.7947538
>       Best valid_loss found so far, saving model...

Epoch 002/250
---------------
> Training on trainset 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 647/647 [Elapsed=00:06, Remaining=00:00, Speed=97.32batch/s, lr=9.962E-05, trainLoss=0.7420747]
>       Done: TRAIN_LOSS = 0.7306052
> Evaluation on validset 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [Elapsed=00:00, Remaining=00:00, Speed= 1.49batch/s, BatchSize=8192]
>       Done: VALID_LOSS = 0.7261569
>       Best valid_loss found so far, saving model...
...
...
...
```

### Developement et docuementation

##### Architecture du projet

Le projet est constitu√© d'un module Python 'balldetect' contenant 

Organisation du dossier du projet:
``` python
- BallDetectionAndForecasting
  - src/                        # Code source du projet
    - balldetect/               # Module 'balldetect'
      - __init__.py
      - ball_detector.py        # Mod√®le de detection de balles (t√¢che 1)
      - datasets.py             # Objets datasets (fourni), cr√©ation des dataloaders et fonction 'retrieve_data'
      - seq_prediction.py       # Mod√®le de pr√©diction de position de balles (t√¢che 2)
      - torch_utils.py          # Fonctions d√©finissant du code commun r√©utilisable: Couches de convolution ou denses; parralelize; Flatten ; tqdm personnalis√©; ... 
      - vis.py                  # Visualization des images avec boundings boxes (fourni)
    - train.py                  # Code utilisant le module 'balldetect' pour entrainer le mod√®le de detection ou de pr√©diction de position de balles
    - hp.py                     # Code de recherche d'hyperparam√®tres
  - notebooks/
    - ball_detection_hp_search_results.ipynb  # Notebook inspectant le r√©sultat des recherches d'hyperparam√®tres
    - test_fastai.ipynb         # Notebook 'brouillon' testant une approche pr√©liminaire au TP avec fastai (tache 1.1)
    - test_fastai-bbox.ipynb    # Notebook 'brouillon'testant une approche pr√©liminaire au TP avec fastai (tache 1.2: version avec bounding-boxes)
  - datasets/
    - mini_balls/
    - mini_balls_seq/
  - download_dataset.sh         # Script de t√©l√©chargement des datasets
  - environement.yml            # Environement conda, d√©finit les d√©pendances
  - LICENSE
  - README.md
  - Rapport.md
  - .gitignore
```

##### Tests pr√©liminaires avec fastai (voir notebooks 'brouillons' ```test_fastai.ipynb``` ```test_fastai-bbox.ipynb```)

Dans un premier temps, avant de coder l'approche avec des mod√®les Pytorch personalis√©s. Des premiers tests on √©t√© fait avec fastai pour avoir une id√©e de la difficult√© de la premi√®re t√¢che et ainsi avoir une baseline. L'approche avec fastai, certes tr√®s peut didactique ou optimis√©e en termes de taille de mod√®le, permet des r√©sultats assez corrects de mani√®re tr√®s rapide. Il s'agissait de tester des mod√®les connus (e.g. variantes de ResNet) pr√©entrainn√©s sur des images ImageNet ou autre. Un rapide fine-tunning sur le dataset de d√©t√©ction de balles permet d'obtenir un detection raisonable en 3-4 lignes de code.  
Une des fonctionalit√©s √©galement interessantes de fastai est l'impl√©mentation d'un m√©thode pour d√©terminer un meilleur learning rate sans avoir √† executer une recherche d'hyperprametres classique (type random-search): le learning rate est d√©termin√© le temps d'une seule √©poque en changeant le learning rate √† chaque batch d'entrainement (voir [callbacks.lr_finder de fastai](https://docs.fast.ai/callbacks.lr_finder.html)).  
Cette approche pr√©liminaire a permit de mieux connaitre les avantages et inconv√©nients d'une utilisation tr√®s basique de fastai (en effet, fastai n'emp√™che pas un controle complet sur le mod√®le entrain√© et la proc√©dure d'entrainement). Les r√©sultats obtenus permettent dans la suite de pouvoir mieux interpreter les valeurs des m√©triques sur ce dataset (donne une baseline raisonnable).


##### Petites optimizations du code

- Le(s) GPU disponnibles seront utilis√©s automatiquement si possible: 

``` python
# Device donn√© en argument de la fonction '.to(DEVICE)' des torch.Tensor
DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
```

- Les dataloaders utilisent plusieur sous-processus en fonction du nombre de coeurs CPU disponnibles sur la machine (param√®tre __```num_workers```__ des Dataloader-s) :

``` python
# Nombre de 'thread' utilis√©s pour chaque dataloader
_DEFAULT_WORKERS = 0 if __debug__ else min(os.cpu_count() - 1, max(1, os.cpu_count() // 4) * max(1, torch.cuda.device_count()))
```

- Pour une meilleure optimization des op√©rations de Pytorch sur GPU, on peut activer l'auto-tuning (bas√© sur un benchmark) de la librairie CuDNN s'ajoutant √† CUDA. CuDNN est une librairie de NVidia (un fichier cpp et une header C++ ajout√© au toolkit CUDA) qui offre des optimisations sp√©cifiques aux r√©seaux de neurones (Convolutions, produits de matrices, calcul du gradient, ...). CuDNN est int√©gr√© √† Pytorch comme pour CUDA qui est simplement une d√©pendance install√©e dans l'environement Conda. 
Pytorch permet d'am√©liorer les performances de CuDNN d'avantage avec les param√®tres __```cudnn.benchmark```__ et __```cudnn.fastest```__. Cependant, activer le benchmarking de CuDNN dans Pytorch peut impacter la reproducibilit√© des r√©sultats √©tant donn√© que ce n'est pas un processus d√©terministe (m√™me avec __```torch.backends.cudnn.deterministic = True```__).  
On observe une am√©lioration de la vitesse d'entrainement entre 30% et 40% pour les mod√®les Pytorch de detection et de pr√©diction de position de balles:

``` python
# Torch CuDNN configuration
torch.backends.cudnn.deterministic = True
cudnn.benchmark = torch.cuda.is_available()  # Enable builtin CuDNN auto-tuner, TODO: benchmarking isn't deterministic, disable this if this is an issue
cudnn.fastest = torch.cuda.is_available()  # Disable this if memory issues
```

- Les performances ont aussi √©t√© un facteur important dans les choix d'hyperparam√®tres et d'architecture des mod√®les (espace de recherche des hyperparametres avec hyperopt). Par exemple, l'architecture du detecteur contient des couches de convolution avec des 'stride' de 2 pour r√©duire la quantit√©e de param√®tres. Les deux mod√®les ont un nombre total de couches relativement faibles. Pareillement, le nombre de filtres de convolution, la taille des filtres (3x3 ou, plus haut dans la convolution, 5x5) et la largeur des couches fully-connected ont √©t√© choisis, en autre, pour √™tre assez faibles √©tant donn√© la simplicit√© aparante de la tache de detection et pour permettre un entrainement plus rapide.

- Les entrainements des mod√®les sont √©galement acc√©l√©r√©s en parallelisant les 'training steps' sur plusieurs GPUs automatiquement avec __``` model = nn.DataParallel(model) ```__ (voir la fonction __``` paralellize(model: nn.Module) -> nn.Module ```__ dans __```./src/balldetect/torch_utils.py```__). Les mod√®les ont √©t√© entrain√© sur une machine personnelle dot√©e de deux NVidia 1080 ti; La paral√®llisation des donn√©es avec cette fonction automatique de Pytorch vas donc executer deux entrainements en parall√®le et synchroniser les gradients √† chaque √©tapes de mani√®re synchrone en calculant la moyenne des deux 'training steps' avant de passer √† l'entrainement sur les prochains batchs.  
De par le besoin de synchronisation des gradients, le mod√®le et/ou les donn√©es/batch_size doivent √™tre assez volumineux pour que cette parall√®lisation offre une acc√©l√©ration de l'entrainement par rapport √† l'utilisation d'un seul GPU.  
Par exemple, on observe pour le mod√®le de detection de balles qu'il faut une __```batch_size```__ sup√©rieure √† 64 pour que les deux 1080 ti soit utilis√©es au del√† de 50% (nvidia-smi). Cependant, trop augmenter la batch_size peut poser des probl√®mes, notamment √† cause de la taille limit√©e du dataset et, pour des mod√®les plus importants, pourrais demander une quantit√©e de m√©moire vid√©o trop grande.  

##### Tache 1: Mod√®le de detection de balles (voir ```./src/balldetect/ball_detector.py``` et les hyperparam√®tres associ√©s dans ```./src/train.py```)

Le mod√®le que nous avons construit pour la detection de balles devait dans un premier temps ne d√©tecter que les couleurs de balles et non leur positions.
Les donn√©es issues du dataset on une redondance au niveau des couleurs de balles (information de coueleur pr√©sente √† la fois dans l'ordre des bounding boxes et dans le vecteur de couleurs). C'est pourquoi nous avons enlev√© les vecteurs nuls des boundings boxes (le vecteur de couleurs d√©finit les bounding boxes gard√©es dans la fonction __```__getitem__```__ de __```balldetect.datasets.BallsCFDetection```__) : le mod√®le fait donne donc en sortie une r√©gression de 3 bounding boxes (3x4 coordonn√©es) et une _multi-label classsification_ pour donner en sortie le vecteur de couleurs (9 valeurs binaires, dont 3 sont √† 1 et les autres √† 0)

La loss utilis√©e pour entrainer le mod√®le est donc l'addiction de deux termes:  
Le premier terme de la loss est la m√©trique BCE () √©valuant la qualit√© de la classification multi-labels sur le vecteur de couleurs.  
Le second terme est une m√©trique MSE (Mean Squared Error) minimisant l'erreur au quarr√© moyenne sur la r√©gression des coordonn√©es des bounding boxes.

Le mod√®le est compos√© d'un '_convolution backbone_' suivit d'une ou plusieurs couches denses (_fully connected layer_). L'architecture du mod√®le contient √©galement des couches __```nn.AvgPooling2d```__ dans le *backbone* de convolutions.  
Nous avons impl√©ment√© l'architecture de mani√®re relativement g√©n√©rique de mani√®re √† pouvoir en d√©finir des variantes dans les hyperparam√®tres facilement.  

Une couche de convolution ou dense (__```nn.Conv2d```__ ou __```nn.Linear```__) peut-√™tre compos√©e d'une fonction d'activation (hyperparametre __```architecture.act_fn```__), de _dropout_ (si __```architecture.dropout_prob != 1.```__), de _batch normalization_ (si __```architecture.batch_norm```__ d√©finit les param√®tres __'eps'__ et __'momentum'__). Voir [./src/balldetect/torch_utils.py](./src/balldetect/torch_utils.py) pour plus de d√©tails sur l'impl√©mentation des couches.  
Pour ce mod√®le, nous avons principalement explor√© les fonctions d'activation __```nn.ReLU```__ et __```nn.LeakyReLU```__.
Les tailles de filtres de convolutions consid√®r√©es sont principalement de __3x3__, __5x5__ et parfois __7x7__ et __1x1__ (avec les padding correspondant).  

Le Mod√®le a √©t√© entrain√© sur le dataset __```mini_balls```__ compos√© de 20000 images. Le dataset est d√©coup√© al√©atoirement en un 'trainset' (90% du dataset) et un 'validset' (10% du dataset). Malheureusement, nous n'avons pas eu le temps d'implementer une cross-validation qui aurais √©t√© utile √©tant donn√© la petite taille du dataset. En effet, dans cette configuration, le validset est un peu trop petit et il risque d'y avoir des instabilit√©s sur les valeurs des m√©triques d'√©valuation qui pourrait, en autre, fausser la recherche d'hyperparam√®tres. De plus, nous n'avons pas cr√©er de 'testset' pour une √©valuation plus ponctuelle par crainte de perdre d'avantage de donn√©es d'entrainement avec un dataset de cette taille, cepandant, il aurait peut-√™tre √©t√© pertinant d'en cr√©er un pour mesurer la pr√©sence d'overfitting sur le validset avec la recherche d'hyperparametres.  

La recherche d'hyperparam√®tre √† permit de trouver de bien meilleurs param√®tres d'entrainement et choisir la bonne variante d'architecture parmit celles d√©finies dans l'espace d'hyperparam√®tres. Nous avons p√ª d√©finir un espace d'hyperparam√®tres relativement restreint √† la lumi√®re des r√©sultats obtenus.  
Ci-dessous, l'espace de recherche des hyperparam√®tres utilis√© avec hyperopt dans __```./src/hp.py```__ (algorithme __```tpe.suggest```__ avec 87 entrainements de 70 epochs et un early_stopping de 12 epochs):

``` python
# Define hyperparameter search space
hp_space = {
    'optimizer_params': {'lr': hp.uniform('lr', 5e-6, 1e-4), 'betas': (0.9, 0.999), 'eps': 1e-8,
                            'weight_decay': hp.loguniform('weight_decay', math.log(1e-7), math.log(1e-3)), 'amsgrad': False},
    'scheduler_params': {'step_size': 40, 'gamma': 0.2},
    # 'scheduler_params': {'max_lr': 1e-2, 'pct_start': 0.3, 'anneal_strategy': 'cos'},
    'batch_size': hp.choice('batch_size', [32, 64, 128]),
    'architecture': {
        'act_fn': nn.LeakyReLU,
        'dropout_prob': hp.choice('dropout_prob', [1., hp.uniform('nonzero_dropout_prob', 0.45, 0.8)]),
        # 'batch_norm': {'eps': 1e-05, 'momentum': 0.1, 'affine': True},
        # Convolutional backbone block hyperparameters
        'conv2d_params': hp.choice('conv2d_params', [
            [{'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1, 'stride': 2},
                {'out_channels': 8, 'kernel_size': (5, 5), 'padding': 2},
                {'out_channels': 8, 'kernel_size': (7, 7), 'padding': 3}],

            [{'out_channels': 2, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1, 'stride': 2},
                {'out_channels': 8, 'kernel_size': (5, 5), 'padding': 2},
                {'out_channels': 8, 'kernel_size': (5, 5), 'padding': 2, 'stride': 2},
                {'out_channels': 16, 'kernel_size': (7, 7), 'padding': 3}],

            [{'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 8, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 8, 'kernel_size': (3, 3), 'padding': 1, 'stride': 2},
                {'out_channels': 16, 'kernel_size': (5, 5), 'padding': 2}],

            [{'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1, 'stride': 4},
                {'out_channels': 8, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 8, 'kernel_size': (3, 3), 'padding': 1}]
        ]),
        # Fully connected head block hyperparameters (a final FC inference layer with no dropout nor batchnorm will be added when ball detector model is instantiated)
        'fc_params': hp.choice('fc_params', [[{'out_features': 64}],
                                                [{'out_features': 64}, {'out_features': 128}],
                                                []])}
}
```

La recherche d'hyperparam√®tres √† donn√©es les param√®tres "optimaux" suivants (best_valid_loss=0.12278, best_train_loss=0.09192 apr√®s 67 epcohs):
TODO:...

``` python
{
  'architecture': {
      'act_fn': nn.LeakyReLU,
      'conv2d_params': ({'kernel_size': (3, 3), 'out_channels': 4, 'padding': 1},
                        {'kernel_size': (3, 3), 'out_channels': 4, 'padding': 1},
                        {'kernel_size': (3, 3), 'out_channels': 8, 'padding': 1},
                        {'kernel_size': (3, 3), 'out_channels': 8, 'padding': 1, 'stride': 2},
                        {'kernel_size': (5, 5), 'out_channels': 16, 'padding': 2}),
      'dropout_prob': 0.7187055,
      'fc_params': []},
  'batch_size': 32,
  'optimizer_params': {'amsgrad': False, 'betas': (0.9, 0.999), 'eps': 1e-08, 'lr': 9.961462262405672e-05, 'weight_decay': 0.0002119238018958741}}
```

L'architecture du mod√®le obtenue avec la recherche d'hyperparam√®tres est la suivante :

![detector_architecture.svg](./figures/detector_architecture.svg)

Nous avons ensuite entrain√© le mod√®le obtenu plus longement et chang√© le scheduling du learning rate pour permettre une meilleure convergance sur un plus grand nombre d'√©pochs en √©vitant l'overfitting: avec ces hyperpram√®tres un learning rate multipli√© par ```gamma=0.2``` toutes les 40 epochs d'entrainement, on obtient: ```best_train_loss=9.0243501``` et ```best_valid_loss=0.0328166``` au bout de la 339√®me epoch.
TODO: ...

Ci dessous quelques r√©sultats obtenus avec ce mod√®le sur des images du validset:  

TODO: ...

##### Tache 2: Mod√®le de pr√©diction de position de balles (voir ```./src/balldetect/seq_prediction.py``` et les hyperparam√®tres associ√©s dans ```./src/train.py```)

Le mod√®le de pr√©diction de position de balles est un simple r√©seaux de neurones dense (fully connected layers) puisque qu'il n'y a pas d'images en entr√©e du mod√®le.  

Pour simplifier l'entrainement du mod√®le, nous avons transform√© les donn√©es pour enlever la redondance d'information sur la couleur des balles. En effet, puisque la couleur des balles ne changent pas dans la s√©quence, nous entrainons le mod√®le pour ne pr√©dire que trois bounding boxes (la position des trois balles donn√©es en entr√©e).  
Nous enlevons donc les vecteurs nuls des boundings boxes en entr√©e (19 x 3 x 4 coordonn√©es) et des bounding box cibles (3 x 4 coordonn√©es). Nous donnons √©galement le vecteur de couleurs (de taille 9) au cas o√π la couleur des balles donerais de l'information sur les propri√©t√©s physiques des balles. Cette simplification des donn√©es permet une convergence bien plus rappide et meilleure.

Le mod√®le est un r√©seaux compos√© uniquement de couches denses (fully connected). Les couches sont d√©finies de mani√®re similaire aux couches denses du mod√®le de d√©tection (t√¢che 1) √† la diff√©rence pr√®s de la fonction d'activation utilis√©e : __```nn.tanh```__ et, biens√ªr, √† leur largeur pr√®s.  

La proc√©dure d'entrainement du mod√®le est relativement similaire √† celle du mod√®le de detection de la tache 1, aux hyperparam√®tres pr√®s. Le mod√®le est entrain√© sur le dataset __```./dataset/mini_balls_seq```__ avec une s√©paration al√©atoire entre validset (10% du dataset) et du trainset (90% du dataset), sans testset pour √©viter de perdre trop de donn√©es, √©tant donn√© la petite taille du dataset. Nous n'avons malheureusement pas p√ª travailler autant que voulut sur l'interpr√®tation de la qualit√© des pr√©dictions faites sur les positions des balles au del√† de la m√©trique utilis√©e, la MSE calcul√©e sur les trois bounding boxes de sortie normalis√©es par le vecteur ```balldetect.datasets.BBOX_SCALE```.  

Ci-dessous, l'espace de recherche d'hyperparam√®tres utilis√©e pour trouver les param√®tres de ce mod√®le:

``` python
{
    'optimizer_params': {'lr': hp.uniform('lr', 5e-6, 1e-4), 'betas': (0.9, 0.999), 'eps': 1e-8, 'weight_decay': hp.loguniform('weight_decay', math.log(1e-7), math.log(1e-2)), 'amsgrad': False},
    'scheduler_params': {'step_size': EPOCHS, 'gamma': 1.},
    # 'scheduler_params': {'max_lr': 1e-2, 'pct_start': 0.3, 'anneal_strategy': 'cos'},
    'batch_size': hp.choice('batch_size', [32, 64, 128]),
    'architecture': {
        'act_fn': hp.choice('batch_size', [nn.LeakyReLU, nn.ReLU, nn.Tanh]),
        'dropout_prob': hp.choice('dropout_prob', [1., hp.uniform('nonzero_dropout_prob', 0.45, 0.8)]),
        # Fully connected network hyperparameters (a final FC inference layer with no dropout nor batchnorm will be added when ball position predictor model is instantiated)
        'fc_params': hp.choice('fc_params', [[{'out_features': 512}, {'out_features': 256}] + [{'out_features': 128}] * 2,
                                              [{'out_features': 128}] + [{'out_features': 256}] * 2 + [{'out_features': 512}],
                                              [{'out_features': 128}] + [{'out_features': 256}] * 3,
                                              [{'out_features': 128}] * 2 + [{'out_features': 256}] * 3,
                                              [{'out_features': 128}] * 2 + [{'out_features': 256}] * 4,
                                              [{'out_features': 128}] * 3 + [{'out_features': 256}] * 4])}
}
```

Le meilleur mod√®le trouv√© √† pour hypererparam√®tres le dictionnaire suivant (**```(best_valid_mse=0.0005018, best_train_mse=0.0005203, at 78th epoch over 90 epochs)```**) :  

``` python
SEQ_PRED_HP = {
    'optimizer_params': {'amsgrad': False, 'betas': (0.9, 0.999), 'eps': 1e-08, 'lr': 5*9.066e-05, 'weight_decay': 2.636e-06},
    'scheduler_params': {'step_size': 30, 'gamma': 0.3},
    'batch_size': 32,
    'architecture': {
        'act_fn': nn.Tanh,
        'dropout_prob': 0.,
        'fc_params': ({'out_features': 512}, {'out_features': 256}, {'out_features': 128}, {'out_features': 128})}
}

# Last hyperparameter search results
SEQU_PRED_HP = {
    'optimizer_params': {'amsgrad': False, 'betas': (0.9, 0.999), 'eps': 1e-08, 'lr': 9.891933484569264e-05, 'weight_decay': 2.0217734556558288e-4},
    'scheduler_params': {'gamma': 0.3, 'step_size': 30},
    'batch_size': 16,
    'architecture': {
        'act_fn': nn.Tanh,
        'dropout_prob': 0.44996724122672166,
        'fc_params': ({'out_features': 512}, {'out_features': 256}, {'out_features': 128}, {'out_features': 128})}
}
```

Une fois ce mod√®le entrain√© sur plus d'epochs et un learning rate scheduler adapt√©, avec 'train.py', nous obtenons les r√©sultats suivants : best_valid_mse=0.0003570, best_train_mse=0.0002038 au bout de la 270√®me epcoh d'entrainement (early stopping √† la 300√®me epoch).  

Ci dessous quelques r√©sultats obtenus avec ce mod√®le sur des s√©quences de boundings boxs du validset:

TODO: ...

La recherche d'hyperparam√®tres n'as pas pu √™tre execut√©e totalement avant le rendu de ce projet, mais les performances du mod√®le d√©finit 'manuellement' semble correctes. Si ces hyperparam√®tres 'manuels' semblent fonctioner, c'est probablement gr√¢ce √† l'√©quilibre entre r√©gularisation et √©chelle du learning rate issue des param√®tres du mod√®le de d√©tection et √©galement gr√¢ce √† la simplification des donn√©es de bounding boxes r√©duites √† 3 par el√©ment de la s√©quence (r√©duction d'un facteur 3 des donn√©es √† inf√®rer et dimminution des donn√©es en entr√©e sans pertes d'informations).

### Conclusion

Pour conclure, d√©velopper et tester des mod√®les Pytorch, certes simples, m'as permit d'approfondir mes connaissances notamment d'un point de vue pratique/technique.  

Il est regrettable que l'investigation et visualisation des r√©sultats souffre probablement d'un manque de temps (ou plut√¥t la cons√©quence des priot√©s donn√©es aux diff√©rents aspects du projet), cepandant, nous avons p√ª d√©velopper des mod√®les Pytorch et des proc√©dures d'entrainement assez fonctionels, complets, g√©n√©rique et r√©utilisables. En effet, ce projet a √©galement √©t√© l'occasion poser une base de code relativement solide pour de futurs projets en Pytorch.

##### Autres pistes et am√©liorations possibles :

+ travailler d'avantage sur l'interpr√®tation, la visualisation et l'investigation des m√©triques et autres r√©sultats obetnus (faite trop tardivement)
+ essayer le *max_polling* en plus ou √† la place du stride de 2 dans les convolution
+ exploiter d'avantage d'a prioris sur le vecteur des couleurs lors de la detection de balles de la t√¢che 1 : sur les 9 valeurs binaires du vecteur de couleurs, 3 sont √† 1 et les autres √† 0, or, notre mod√®le est entrain√© pour faire une classification multi-classes (vecteur de couleurs en sortie de taille 9 avec une BCE loss) alors qu'il pourait s'agir de classifier 3 valeurs (comprises entre 0 et 8) repr√©santant les index des valeurs √† 1 dans le vecteur de couleurs. Cepandant, il n'est pas certains que cette approche am√©liorerais les performances puisque pr√©dire une 'simili-lookup table' (ou embedding layer) a ses avantages : empiriquement on constate souvent que la qualit√© des pr√©dictions est meilleures ainsi (probablement car les gradients sont moins 'intriqu√©s' en sortie et chaque possiblit√©es de classification √† une sortie d√©di√©e, donc un parcours dans le r√©seaux plus ind√©pendant).
+ finir l'impl√©mentation de la sauvegarde de mod√®les et du logging des m√©triques pour tensorboard (utilisation de tensorboard avec Pytorch pour mieux diagnostiquer et visualiser l'entrainement et les r√©sultats).
+ voir si enlever la redondance d'information entre couleurs et bounding boxes n'as pas finalement compliqu√© l'entrainement de par le fait que l'ordre des boundings boxes √† inf√©rer en sortie des mod√®les est plus complexe/intriqu√©e (la loss seras compl√®tement diff√©rente si les 3 bounding boxes en sortie sont dans un ordre diff√©rent, m√™me si elles restent identiques). Il faudrais investiger ce probl√®me et essayer des workaround (comme par exemple, une loss invariante √† l'ordre des bounding boxes inf√©r√©es).
+ exploiter l'as prioris sur les coordonn√©es des bounding boxes: non seulement les coordonn√©es sont dans un certain ordre mais, dans ce dataset, toutes les balles sont environs de la m√™me taille, ont pourrait donc simplement faire une regression sur, par exemple, la moyennes des deux coordonn√©es d'une bounding box (centre de la balle). De mani√®re moins agressive, on pourrait ajouter un terme dans la loss encouragant un certain ordre entre les valeurs des coordonn√©es des bounding boxes.
+ utiliser la mean average precision combin√©e avec une m√©trique _d'Intersection over Union_ (IoU) pour la regression des bounding boxes, comme utilis√©e sur le dataset Pascal VOC
+ dans la loss du mod√®le de detection de balles : ajouter un facteur multipliant la loss BCE sur la classification des couleurs pour √©quilibrer l'importance de ce terme dans la loss par rapport √† la MSE de la r√©gression des bounding boxes.
+ utiliser de la cross validation √©tant donn√© la petite taille du dataset (de plus, de par une erreur pendant les recherches d'hyperparametres, le validset ne faisait que 1.5% de la taille du dataset, il repr√©sente maintenant 10% du dataset mais l'id√©al serait que le dataset soit plus grand (ou crossvalidation) pour √©viter des probl√®mes d'impr√©cision sur les m√©triques sur le validset sans pour autant que le trainset ne soit trop r√©duit)
+ cr√©er un petit testset pour √©valuer tr√®s ponctuellement le mod√®le autrement que par le validset qui pourrait √™tre compromis par la recherche d'hyperparam√®tres
+ utiliser des m√©thodes de recherche d'hyperparam√®tres plus efficaces (e.g. la m√©thode utilis√©e par fastai dans [callbacks.lr_finder](https://docs.fast.ai/callbacks.lr_finder.html): [post de blog de Sylvain Gugger](https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html)) et utilisation de [microsoft/nni](https://github.com/microsoft/nni) regroupant de nombreuses de m√©thodes de recherche d'hyperparam√®tres)
+ utiliser des m√©thodes de recherche d'architecture automatiques (beaucoup d'engouement/progr√®s dans la communaut√© deeplearning autour des m√©thodes de "neural net architecture search" et "meta-learning")
+ tests plus pouss√©s du scheduling de learning rate (e.g. investiger pourquoi OneCycle learning rate scheduler n'a pas donn√© de r√©sultats probants sur la d√©tection de balles avec notre mod√®l)
+ tests plus pouss√©s avec de la batch norm: impl√©ment√©e mais tr√®s peu test√©e pour r√©duire l'espace de recherche d'hyperparam√®tres de par le manque de temps (mais dropout, weight decay, .. utilis√©)
+ utiliser de l'augmentation de donn√©es aurait p√ª √™tre int√©ressant
+ comparer les r√©sultats et approches avec le papier https://arxiv.org/pdf/1909.12000.pdf

<img width=250 src="./figures/logo_insa.jpg"/>

*Copyright (c) 2019 Paul-Emmanuel SOTIR*  
*__This project and document is under open-source MIT license, browse to: https://github.com/PaulEmmanuelSotir/BallDetectionAndForecasting/blob/master/LICENSE for full MIT license text.__*
