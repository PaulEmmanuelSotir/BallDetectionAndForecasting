# ü¶èüéì RAPPORT TP DEEP LEARNING - INSA Lyon 5IF üéìü¶è
_Paul-Emmanuel SOTIR <paul-emmanuel.sotir@insa-lyon.fr> <paul-emmanuel@outlook.com>_
- Course link https://perso.liris.cnrs.fr/christian.wolf/teaching/deeplearning/tp.html
- Github repository: https://github.com/PaulEmmanuelSotir/BallDetectionAndForecasting
  
### Introduction

...

##### Tache 1 : detection de balles

...

##### Tache 2 : pr√©diction de la position future de balles

...

### Run instructions

Les d√©pendences du projets sont g√®r√©es avec un environement conda; Il suffit donc d'une distribution conda (e.g. Anconda ou Miniconda) et de cr√©er l'environement conda pour pouvoir executer le code :  

``` shell
############## Installation ##############

git clone git@github.com:PaulEmmanuelSotir/BallDetectionAndForecasting.git
conda env create -f ./environement.yml
conda activate pytorch_5if
# T√©l√©charge les datasets (nescessite les packages 'curl' et 'tar' sur une distribution Linux (ou WSL - Linux subsystem on Windows))
bash ./download_dataset.sh

############## Exemples d'utilisation ##############

# Entraine le mod√®le de d√©tection de balles (tache 1) avec les meilleurs hyperparam√®tres trouv√©s
python ./src/train.py --detect
# Execute une recherche d'hyperparam√®tres pour la detection de balles (hyperopt)
python ./src/train.py --detect
# Entraine le mod√®le de pr√©diction de position de balles (tache 2) avec les meilleurs hyperparam√®tres trouv√©s
python ./src/train.py --pred_seq
# Execute une recherche d'hyperparam√®tres pour la pr√©diction de position de la balles (hyperopt)
python ./src/train.py --pred_seq
```

### Developement et docuementation

##### Architecture du projet

Le projet est constitu√© d'un module Python 'balldetect' contenant 

Organisation du dossier du projet:
``` python
- BallDetectionAndForecasting
  - src/                        # Code source du projet
    - balldetect/               # Module 'balldetect'
      - __init__.py
      - ball_detector.py        # Mod√®le de detection de balles (t√¢che 1)
      - datasets.py             # Objets datasets (fourni) et cr√©ation des dataloaders
      - seq_prediction.py       # Mod√®le de pr√©diction de position de balles (t√¢che 2)
      - torch_utils.py          # Fonctions d√©finissant du code commun aux deux mod√®les: Couches de convolution (ConvLayer); Couches denses (FCLayer); parralelize (nn.DataParallel), flatten et progress_bar (tqdm personnalis√©); 
      - vis.py                  # Visualization des images avec boundings boxes (fourni)
    - train.py                  # Code utilisant le module 'balldetect' pour entrainer le mod√®le de detection ou de pr√©diction de position de balles
    - hp.py                     # Code de recherche d'hyperparam√®tres
  - notebooks/
    - BallDetection.ipynb       # Notebook 'brouillon' pour le test et le developpement de code
    - test_fastai.ipynb         # Notebook 'brouillon' testant une approche pr√©liminaire au TP avec fastai (tache 1.1)
    - test_fastai-bbox.ipynb    # Notebook 'brouillon'testant une approche pr√©liminaire au TP avec fastai (tache 1.2: version avec bounding-boxes)
  - datasets/
    - mini_balls/
    - mini_balls_seq/
  - download_dataset.sh         # Script de t√©l√©chargement des datasets
  - environement.yml            # Environement conda, d√©finit les d√©pendances
  - LICENSE
  - README.md
  - Rapport.md
  - .gitignore
```

##### Petites optimizations du code

- Le(s) GPU disponnibles seront utilis√©s automatiquement si possible: 

``` python
# Device donn√© en argument de la fonction '.to(DEVICE)' des torch.Tensor
DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
```

- Les dataloaders utilisent plusieur sous-processus en fonction du nombre de coeurs CPU disponnibles sur la machine (param√®tre __```num_workers```__ des Dataloader-s) :

``` python
# Nombre de 'thread' utilis√©s pour chaque dataloader
_DEFAULT_WORKERS = 0 if __debug__ else min(os.cpu_count() - 1, max(1, os.cpu_count() // 4) * max(1, torch.cuda.device_count()))
```

- Pour une meilleur optimization des op√©rations de Pytorch sur GPU, on peut activer l'auto-tuning (bas√© sur un benchmark) de la librairie CuDNN s'ajoutant √† CUDA. CuDNN est une librairie de NVidia (un fichier cpp et une header C++ ajout√© au toolkit CUDA) qui offre des optimisations sp√©cifiques aux r√©seaux de neurones (Convolutions, produits de matrices, calcul du gradient, ...). CuDNN est int√©gr√© √† Pytorch comme pour CUDA qui est simplement une d√©pendance install√©e dans l'environement Conda. Pytorch permet d'am√©liorer les performances de CuDNN d'avantage avec les param√®tres __```cudnn.benchmark```__ et __```cudnn.fastest```__.
On observe une am√©lioration de la vitesse d'entrainement entre 30% et 40% pour les mod√®les Pytorch de detection et de pr√©diction de position de balles:

``` python
# Torch CuDNN configuration
cudnn.benchmark = torch.cuda.is_available()  # Enable builtin CuDNN auto-tuner
cudnn.fastest = torch.cuda.is_available()  # Disable this if memory issues
```

- Les performances ont aussi √©t√© un facteur important dans les choix d'hyperparam√®tres et d'architecture des mod√®les (espace de recherche des hyperparametres avec hyperopt). Par exemple, l'architecture du detecteur contient des couches de convolution avec des 'stride' de 2 pour r√©duire la quantit√©e de param√®tres. Les deux mod√®les ont un nombre total de couches relativement faibles. Pareillement, le nombre de filtres de convolution, la taille des filtres (3x3 ou, plus haut dans la convolution, 5x5) et la largeur des couches fully-connected ont √©t√© choisis, en autre, pour √™tre assez faibles √©tant donn√© la simplicit√© aparante de la tache de detection et pour permettre un entrainement plus rapide.

- Les entrainements des mod√®les sont √©galement acc√©l√©r√©s en parallelisant les 'training steps' sur plusieurs GPUs automatiquement avec __``` model = nn.DataParallel(model) ```__ (voir la fonction __``` paralellize(model: nn.Module) -> nn.Module ```__ dans __```./src/balldetect/torch_utils.py```__). Les mod√®les ont √©t√© entrain√© sur une machine personnelle dot√©e de deux NVidia 1080 ti; La paral√®llisation des donn√©es avec cette fonction automatique de Pytorch vas donc executer deux entrainements en parall√®le et synchroniser les gradients √† chaque √©tapes de mani√®re synchrone en calculant la moyenne des deux 'training steps' avant de passer √† l'entrainement sur les prochains batchs.  
De par le besoin de synchronisation des gradients, le mod√®le et/ou les donn√©es/batch_size doivent √™tre assez volumineux pour que cette parall√®lisation offre une acc√©l√©ration de l'entrainement par rapport √† l'utilisation d'un seul GPU.  
Par exemple, on observe pour le mod√®le de detection de balles qu'il faut une ```batch_size``` sup√©rieure √† 64 pour que les deux 1080 ti soit utilis√©es au del√† de 50% (nvidia-smi). Cependant, trop augmenter la batch_size peut poser des probl√®mes, notamment √† cause de la taille limit√©e du dataset et, pour des mod√®les plus importants, pourrais demander une quantit√©e de m√©moire vid√©o trop grande.  

##### Tests pr√©liminaires avec fastai (voir notebooks 'brouillons' ```test_fastai.ipynb``` ```test_fastai-bbox.ipynb```)

Dans un premier temps, avant de coder l'approche avec des mod√®les Pytorch personalis√©s. Des premiers tests on √©t√© fait avec fastai pour avoir une id√©e de la difficult√© de la premi√®re t√¢che et ainsi avoir une baseline. L'approche avec fastai, certes tr√®s peut didactique ou optimis√©e en termes de taille de mod√®le, permet des r√©sultats assez corrects de mani√®re tr√®s rapide. Il s'agissait de tester des mod√®les connus (e.g. variantes de ResNet) pr√©entrainn√©s sur des images ImageNet ou autre. Un rapide fine-tunning sur le dataset de d√©t√©ction de balles permet d'obtenir un detection raisonable en 3-4 lignes de code.  
Une des fonctionalit√©s √©galement interessantes de fastai est l'impl√©mentation d'un m√©thode pour d√©terminer un meilleur learning rate sans avoir √† executer une recherche d'hyperprametres classique (type random-search): le learning rate est d√©termin√© le temps d'une seule √©poque en changeant le learning rate √† chaque batch d'entrainement (voir [callbacks.lr_finder de fastai](https://docs.fast.ai/callbacks.lr_finder.html)).  
Cette approche pr√©liminaire a permit de mieux connaitre les avantages et inconv√©nients d'une utilisation tr√®s basique de fastai (en effet, fastai n'emp√™che pas un controle complet sur le mod√®le entrain√© et la proc√©dure d'entrainement). Les r√©sultats obtenus permettent dans la suite de pouvoir mieux interpreter les valeurs des m√©triques sur ce dataset (donne une baseline raisonnable).

##### Tache 1: Mod√®le de detection de balles (voir ```./src/balldetect/ball_detector.py``` et les hyperparam√®tres associ√©s dans ```./src/train.py```)

Le mod√®le que nous avons construit pour la detection de balles devait dans un premier temps ne d√©tecter que les couleurs de balles et non leur positions.

La loss utilis√©e pour entrainer le mod√®le ... TODO: ...

La recherche d'hyperparam√®tre √† permit de trouver de bien meilleurs param√®tres d'entrainement et choisir la bonne variante d'architecture parmit celles d√©finies dans l'espace d'hyperparam√®tres.  
Est donn√© ci-dessous l'espace de recherche des hyperparam√®tres donn√© √† hyperopt (algorithme ```tpe.suggest``` avec 200 entrainements de 70 epochs et un early_stopping de 12 epochs):

``` python
# Define hyperparameter search space
hp_space = {
    'optimizer_params': {'lr': hp.uniform('lr', 5e-6, 1e-4), 'betas': (0.9, 0.999), 'eps': 1e-8,
                            'weight_decay': hp.loguniform('weight_decay', math.log(1e-7), math.log(1e-3)), 'amsgrad': False},
    # 'scheduler_params': {'max_lr': 1e-2, 'pct_start': 0.3, 'anneal_strategy': 'cos'},
    'batch_size': hp.choice('batch_size', [32, 64, 128]),
    'architecture': {
        'act_fn': nn.LeakyReLU,
        # TODO: Avoid enabling both dropout and batch normalization at the same time: 1ee ...
        'dropout_prob': hp.choice('dropout_prob', [1., hp.uniform('nonzero_dropout_prob', 0.45, 0.8)]),
        # 'batch_norm': {'eps': 1e-05, 'momentum': 0.1, 'affine': True},
        # Convolutional backbone block hyperparameters
        'conv2d_params': hp.choice('conv2d_params', [
            [{'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1, 'stride': 2},
                {'out_channels': 8, 'kernel_size': (5, 5), 'padding': 2},
                {'out_channels': 8, 'kernel_size': (7, 7), 'padding': 3}],

            [{'out_channels': 2, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1, 'stride': 2},
                {'out_channels': 8, 'kernel_size': (5, 5), 'padding': 2},
                {'out_channels': 8, 'kernel_size': (5, 5), 'padding': 2, 'stride': 2},
                {'out_channels': 16, 'kernel_size': (7, 7), 'padding': 3}],

            [{'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 8, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 8, 'kernel_size': (3, 3), 'padding': 1, 'stride': 2},
                {'out_channels': 16, 'kernel_size': (5, 5), 'padding': 2}],

            [{'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 4, 'kernel_size': (3, 3), 'padding': 1, 'stride': 4},
                {'out_channels': 8, 'kernel_size': (3, 3), 'padding': 1},
                {'out_channels': 8, 'kernel_size': (3, 3), 'padding': 1}]
        ]),
        # Fully connected head block hyperparameters (a final FC inference layer with no dropout nor batchnorm will be added when ball detector model is instantiated)
        'fc_params': hp.choice('fc_params', [[{'out_features': 64}],
                                                [{'out_features': 64}, {'out_features': 128}],
                                                []])}
}
```

La recherche d'hyperparam√®tres √† donn√©es les param√®tres "optimaux" suivants (best_valid_loss=0.12278, best_train_loss=0.09192 apr√®s 67 epcohs):

``` python
{'architecture': {
	'act_fn': nn.LeakyReLU,
	'conv2d_params': ({'kernel_size': (3, 3), 'out_channels': 4, 'padding': 1},
			  {'kernel_size': (3, 3), 'out_channels': 4, 'padding': 1},
			  {'kernel_size': (3, 3), 'out_channels': 8, 'padding': 1},
			  {'kernel_size': (3, 3), 'out_channels': 8, 'padding': 1, 'stride': 2},
			  {'kernel_size': (5, 5), 'out_channels': 16, 'padding': 2}),
	'dropout_prob': 0.7187055796612525,
	'fc_params': ()},
	'batch_size': 32,
	'optimizer_params': {'amsgrad': False, 'betas': (0.9, 0.999), 'eps': 1e-08, 'lr': 9.961462262405672e-05, 'weight_decay': 0.0002119238018958741}}
```

(voir la section __"R√©sultats/Resultats tache 1"__ ci-dessous pour plus de d√©tails sur les detection faites par ce mod√®le)

##### Tache 2: Mod√®le de pr√©diction de position de balles (voir ```./src/balldetect/seq_prediction.py``` et les hyperparam√®tres associ√©s dans ```./src/train.py```)

Le mod√®le de pr√©diction de position de balles est un simple r√©seaux de neurones dense (fully connected layers) puisque qu'il n'y a pas d'images en entr√©e du mod√®le.  

La proc√©dure d'entrainement du mod√®le est relativement similaire √† celle du mod√®le de detection de la tache 1, aux hyperparam√®tres pr√®s. Nous n'avons malheureusement pas eu le temps d'executer une recherche d'hyperparam√®tres pour ce mod√®le. De m√™me, par manque de temps, nous n'avons pas p√ª travailler autant que voulut sur l'am√©lioration de ce mod√®le et l'interpr√®tation de la qualit√© des pr√©dictions faites sur les positions des balles au del√† de la m√©trique utilis√©e (voir la section __"R√©sultats/Resultats tache 2"__ ci-dessous)

### R√©sultats

##### Resultats tache 1 : Detection des balles

Voici un tableau r√©capitulant les r√©sultats obtenus avec nos mod√®les: Mod√®le pr√©liminaire fastai; Mod√®le inf√©rant seulement la pr√©sence de couleurs de balles; Mod√®le final inf√©rant les couleurs et position des balles dans l'image d'entr√©e.

![task1_results]()

##### Resultats tache 2 : Pr√©diction de la position de balles

Voici un tableau r√©capitulant les r√©sultats obtenus avec notre mod√®le de pr√©diction de la position future de la balle √† partir de sa position pr√©c√©dente :

![task2_results]()

### Conclusion

Pour conclure, d√©velopper et tester des mod√®les Pytorch, certes simples, m'as permit d'approfondir mes connaissances notamment d'un point de vue pratique/technique.  

Il est regrettable que la qualit√© du mod√®le de la t√¢che 2 souffre probablement d'un manque de temps (ou plut√¥t d'une meilleure mise en priot√© des diff√©rents aspects du projet), cepandant, nous avons p√ª d√©velopper des mod√®les Pytorch et des proc√©dures d'entrainement assez complet, g√©n√©rique et r√©utilisable. En effet, ce projet a √©galement √©t√© l'occasion poser une base de code relativement solide pour de futurs projets.

##### Autres pistes et am√©liorations possibles

+ redondance entre couleurs et bounding boxes
+ recherche d'hyperparam√®tres pour la pr√©diction de position future des balles
+ m√©thodes de recherche d'hyperparam√®tres plus efficaces (e.g. la m√©thode utilis√©e par fastai dans [callbacks.lr_finder](https://docs.fast.ai/callbacks.lr_finder.html): [post de blog de Sylvain Gugger](https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html)) et utilisation de [microsoft/nni](https://github.com/microsoft/nni) regroupant de nombreuses de m√©thodes de recherche d'hyperparam√®tres)
+ utiliser des m√©thodes de recherche d'architecture automatiques (beaucoup d'engouement/progr√®s dans la communaut√© deeplearning autour des m√©thodes de "neural net architecture search" et "meta-learning")
+ tests plus pouss√©s du scheduling de learning rate (e.g. investiger pourquoi OneCycle learning rate scheduler n'a pas donn√© de r√©sultats probants sur la d√©tection de balles avec notre mod√®l)
+ tests plus pouss√©s avec de la batch norm: impl√©ment√©e mais tr√®s peu test√©e pour r√©duire l'espace de recherche d'hyperparam√®tres de par le manque de temps (mais dropout, weight decay, .. utilis√©)
+ Utiliser de l'augmentation de donn√©es aurait p√ª √™tre int√©ressant

![Logo INSA Lyon](https://www.insa-lyon.fr/sites/www.insa-lyon.fr/files/logo-coul.jpg =200x))
_Copyright (c) 2019 Paul-Emmanuel SOTIR_  
**_This project and document is under open-source MIT license, browse to: https://github.com/PaulEmmanuelSotir/BallDetectionAndForecasting/blob/master/LICENSE for full MIT license text._**
